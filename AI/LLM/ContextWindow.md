One of the largest (no pun intended) limitations of Large Language Models (LLMs) is their context window size. Here's an overview of the most popular LLMs and their context window size:

Model Max tokens Words (estimated)
gpt-4 8,192 6,120
gpt-4-32k 32,768 24,000
gpt-3.5-turbo 4,096 3,067
gpt-3.5-turbo-16k 16,385 12,000
Claude 2 100,000 75,000
Llama 2 4,096 3,067

## MemGPT

- https://www.mlexpert.io/blog/memgpt
  MemGPT, introduced in the paper "MemGPT: Towards LLMs as Operating Systems"1, helps large language models (LLMs) handle longer conversations by cleverly managing different memory tiers. It knows when to store important information and retrieve it later during a chat. This makes it possible for AI models to have extended conversations, greatly improving their usefulness.
